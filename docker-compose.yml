version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
    - "2181:2181"
  kafka:
    image: wurstmeister/kafka:latest
    ports:
    - "9092:9092"
    environment:
      HOSTNAME_COMMAND: "getent hosts host.docker.internal | awk '{ print $$1 }'"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
    volumes:
    - "/var/run/docker.sock:/var/run/docker.sock"
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.1.1-java8
    volumes:
    - "namenode-data:/hadoop/dfs/name"
    environment:
      CLUSTER_NAME: "test"
    env_file:
    - ./hadoop.env
    ports:
    - "50070:50070"
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.1.1-java8
    depends_on:
    - namenode
    volumes:
    - "datanode-data:/hadoop/dfs/data"
    env_file:
    - ./hadoop.env
    ports:
    - "50075:50075"
  spark-master:
    image: bde2020/spark-master:2.3.2-hadoop3.1.1-java8
    ports:
    - "8080:8080"
    - "7077:7077"
    env_file:
    - ./hadoop.env
  spark-worker:
    image: bde2020/spark-worker:2.3.2-hadoop3.1.1-java8
    depends_on:
    - spark-master
    environment:
      SPARK_MASTER: "spark://spark-master:7077"
    ports:
    - "8081:8081"
    env_file:
    - ./hadoop.env
  spark-notebook:
    image: bde2020/spark-notebook:2.1.0-hadoop2.8-hive
    env_file:
    - ./hadoop.env
    ports:
    - "9001:9001"
  hue:
    image: bde2020/hdfs-filebrowser:3.11
    ports:
    - "8088:8088"
    environment:
      NAMENODE_HOST: "namenode"
volumes:
  namenode-data:
  datanode-data:
